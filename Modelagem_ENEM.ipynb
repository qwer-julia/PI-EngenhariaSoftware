# Modelagem_ENEM.ipynb

# ======================================
# 1. Setup
# ======================================
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import shap

# Carregar dataset parquet
enem = pd.read_parquet("enem_censo.parquet")

# ======================================
# 2. Seleção de Features
# ======================================
features = ["Q001", "Q002", "IN_LAB_CIENCIAS", "IN_BIBLIOTECA", "IN_INTERNET"]  # Exemplo
target = "NU_NOTA_MT"

# Encoder simples (transformar categóricas em numéricas)
enem_enc = pd.get_dummies(enem[features + [target]], drop_first=True)

X = enem_enc.drop(columns=[target])
y = enem_enc[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ======================================
# 3. Modelo
# ======================================
model = RandomForestRegressor(n_estimators=200, random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("RMSE:", mean_squared_error(y_test, y_pred, squared=False))
print("R²:", r2_score(y_test, y_pred))

# ======================================
# 4. SHAP
# ======================================
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# Gráfico de importância global
shap.summary_plot(shap_values, X_test)

# Explicação individual (primeiro aluno do teste)
shap.force_plot(explainer.expected_value, shap_values[0,:], X_test.iloc[0,:])
